\newpage
%
%	Аппроксимация функция
%
\section{Аппроксимация функция}
Задача о приближении функции ставится следующим образом:
данную функцию $f(x)$ необходимо заменить 
обобщенным полиномом $p_m(x)$ заданного порядка $m$ 
так, чтобы отклонение (в известном смысле) функции $f(x)$ 
от обобщенного полинома $p_m(x)$ на указанном множестве 
$\vect{x}=\{x\}$ было наименьшим. 
При этом полином $p_m(x)$ в общем случае 
называется аппроксимирующим.

Если множество $\vect{x}$ состоит из отдельных точек 
$x\in\{x_0, x_1, x_2, \dots x_n\}$ (узлов),
то приближение называется \emph{точечным}.
Если $\vect{x}$ есть отрезок $x_a<x<x_b$, 
то приближение называется \emph{интегральным}. 
Для практики важным является приближение функций 
алгебраическими и тригонометрическими полиномами.

\emptyline
\subsection{Точечное квадратичное аппроксимирование функций}
На практике часто бывает, что заданный порядок $m$ 
приближающего полинома $p_m(x)$ меньше числа 
узлов аппроксимации ${m<n}$, в которых 
известно значение функции $y_i=f(x_i)$ ($i=0,1,2, \cdots, n$).
В этом случае обычно используют точечный 
метод наименьших квадратов и
рассматривается алгебраический полином степени $m$ вида:
\begin{gather*}
p_m(x)=c_0+c_1\cdot{x}+c_2\cdot{x^2}+\dots+c_m\cdot{x^m}=
\sum\limits_{j=0}^{m}c_j\cdot{x^j}.
\end{gather*}

В качестве меры отклонения $\norma{r}$ полинома $p_m(x)$ 
от известной функции $y(x)$ на множестве точек 
$\{x_0, x_1, x_2,\cdots,x_n\}$, как правило, принимается 
сумма квадратов отклонений полинома от этой функции 
на заданной системе точек:
\begin{gather*}
\norma{r}=\sum_{i=0}^{n}\left(p_m(x_i)-y_i\right)^2
\end{gather*}

Следует отметить, что мера отклонения полинома 
от известной функции есть функция многих переменных
$\norma{r}=\rho(c_0, c_1, \dots, c_m)$, т.е. коэффициентов полинома
$c_i$ ($i=0,1,\dots,m$), которые необходимо подобрать так, 
чтобы величина меры отклонения была наименьшей 
$\norma{r}\to{\min}$.
Полученный полином называется аппроксимирующим 
для данной функции, а процесс построения этого полинома -- 
точечной квадратичной аппроксимацией или 
точечным квадратичным аппроксимированием функции. 

Для решения задачи точечного квадратичного аппроксимирования,
т.е. определения числовых значений всех коэффициентов 
полинома $p_m(x)$, необходимо найти \emph{положения минимума 
функции} многих переменных $\rho(c_0,c_1,\ldots,c_m)$.

Определим частные производные от величины суммы квадратов отклонений и 
воспользовавшись условием экстремума функции многих переменных, 
составим систему уравнений вида:
\begin{gather*}
\pdiff{\rho}{c_0}=
\pdiff{\rho}{c_1}=
\pdiff{\rho}{c_2}=\cdots=
\pdiff{\rho}{c_m}=0
\end{gather*}

Для определения неизвестных коэффициентов полинома
$c_0, c_1, c_2,\dots, c_m$ необходимо решить систему 
$m+1$ уравнений с $m+1$ неизвестными: 
\begin{gather*}
\renewcommand*{\arraystretch}{1.5}
\left\{\begin{array}{lclcl}
\pdiff{\rho}{c_0}&=&2\cdot\sum\limits_{i=0}^{n}\left(c_0+c_1\cdot{x_i}+c_2\cdot{x_i^2}+\ldots+c_m\cdot{x_i^m} - y_i\right)\cdot1&=&0\\
\pdiff{\rho}{c_1}&=&2\cdot\sum\limits_{i=0}^{n}\left(c_0+c_1\cdot{x_i}+c_2\cdot{x_i^2}+\ldots+c_m\cdot{x_i^m} - y_i\right)\cdot{x_i}&=&0\\
\pdiff{\rho}{c_2}&=&2\cdot\sum\limits_{i=0}^{n}\left(c_0+c_1\cdot{x_i}+c_2\cdot{x_i^2}+\ldots+c_m\cdot{x_i^m} - y_i\right)\cdot{x_i^2}&=&0\\
\hdotsfor{1}&=&\hdotsfor{1}&=&0\\
\pdiff{\rho}{c_m}&=&2\cdot\sum\limits_{i=0}^{n}\left(c_0+c_1\cdot{x_i}+c_2\cdot{x_i^2}+\ldots+c_m\cdot{x_i^m} - y_i\right)\cdot{x_i^m}&=&0\\
\end{array}\right.
\end{gather*}

Таким образом, задача точечной квадратичной аппроксимации 
функции сводится к решению системы линейных уравнений 
относительно неизвестных -- коэффициентов полинома 
$\{c_0, c_1, c_2,\dots, c_m\}$:
\begin{gather*}
\begin{matrix}
\mathbf{A}\cdot\vect{c}=\vect{b}
&\text{или}&
\begin{pmatrix}
a_{00}&a_{01}&\cdots&a_{0m}\\
a_{10}&a_{11}&\cdots&a_{1m}\\
\vdots&\vdots&\ddots&\vdots\\
a_{m0}&a_{m1}&\cdots&a_{mm}\\
\end{pmatrix}
\cdot
\begin{pmatrix}c_0\\c_1\\\vdots\\c_m\end{pmatrix}
=\begin{pmatrix}b_0\\b_1\\\vdots\\b_m\end{pmatrix}
\end{matrix},\end{gather*}
где $\mathbf{A}=\{a_{k\ell}\}$ и $\vect{b}=\{b_k\}$ 
-- квадратная матрица и вектор правых частей 
системы линейных уравнений, соответственно:
\begin{gather*}
a_{k\ell}=\sum\limits_{i=0}^n x_i^k\cdot x_i^\ell,
\quad
b_{k}=\sum\limits_{i=0}^n x_i^k\cdot y_i,
\quad k,\ell=0,1,2,\dots,m
\end{gather*}

Если среди узлов сетки $\{x_i\}$ 
нет совпадающих, а также степень полинома 
меньше чем число узлов аппроксимации $m<n$, 
то определитель системы не равен нулю $\det\mathbf{A}\ne0$.
Следовательно, эта система имеет единственное решение 
$\mathring{\vect{c}}=\{\mathring{c}_0, \mathring{c}_1, \mathring{c}_2,\dots, \mathring{c}_m\}$,
а полином $p_m(x)$ с такими коэффициентами $\mathring{c}_i$ 
будет обладать минимальным квадратичным отклонением 
$\rho_{\min}$. 

%
%	Аппроксимирования функций полиномом второй степени $p_2(x)$
%
\emptyline
\subsection{Аппроксимирования функций полиномом
второй степени $p_2(x)$}
Известна таблица данных некоторой функциональной зависимости 
$y(x)$:
\begin{table}[H]
\vspace{-0.5\baselineskip}
\caption{Таблично заданная функциональная зависимость
$y_i=f(x_i)$}
\begin{tabular*}{\textwidth}{%
l@{\extracolsep{\fill}}*{5}{r}p{0.25cm}}
\toprule
$i$&$0$&$1$&$2$&$3$&$4$\\
\midmidrule
$x_i$&$-0.76$&$-0.48$&$-0.09$&$0.22$&$0.55$\\
$y_i$&$5.15$&$4.39$&$4.10$&$5.71$&$5.30$\\
\bottomrule
\end{tabular*}
\end{table}

Необходимо аппроксимировать функцию $\{y_i\}$,
заданную таблично, алгебраическим полиномом 
второй степени $p_2(x)$:
\begin{gather*}
p_2(x)=c_0 + c_1\cdot x + c_2\cdot x^2
\end{gather*}

\begin{enumerate}
\item
Построим меру отклонения полинома $p_2(x)$ 
от таблично заданной функции $y_i=f(x_i)$
на множестве точек $\{x_0, x_1, x_2, x_3, x_4\}$:
\begin{gather*}
\norma{r}=\rho(c_0,c_1,c_2)=
\sum_{i=0}^{4}\left(c_0+c_1\cdot{x_i}+c_2\cdot{x_i^2}-y_i\right)^2,
\end{gather*}
где $y_i=f(x_i)$ -- значение функции в точке $x_i$.

\item
Запишем меру отклонения $\rho(c_0,c_1,c_2)$ в явном виде 
на основе данных из условия задачи:
\begin{gather*}
\begin{split}
\rho(c_0,c_1,c_2)=
&\left(c_0 + c_1\cdot(-0.76) + c_2\cdot(-0.76)^2 - 5.15 \right)^2+\\
&\left(c_0 + c_1\cdot(-0.48) + c_2\cdot(-0.48)^2 - 4.39 \right)^2+\\
&\left(c_0 + c_1\cdot(-0.09) + c_2\cdot(-0.09)^2 - 4.10 \right)^2+\\
&\left(c_0 + c_1\cdot(0.22) + c_2\cdot(0.22)^2 - 5.71 \right)^2+\\
&\left(c_0 + c_1\cdot(0.55) + c_2\cdot(0.55)^2 - 5.30 \right)^2
\end{split}
\end{gather*}

\item
Определим частную производную от меры отклонений $\rho(c_0,c_1,c_2)$ 
по аргументу $c_0$ и приравняем её нулю:
\begin{gather*}
\begin{split}
\pdiff{\rho}{c_0}=
&2\cdot\left(c_0 + c_1\cdot(-0.76) + c_2\cdot(-0.76)^2 - 5.15 \right)\cdot 1+\\
&2\cdot\left(c_0 + c_1\cdot(-0.48) + c_2\cdot(-0.48)^2 - 4.39 \right)\cdot 1+\\
&2\cdot\left(c_0 + c_1\cdot(-0.09) + c_2\cdot(-0.09)^2 - 4.10 \right)\cdot 1+\\
&2\cdot\left(c_0 + c_1\cdot(0.22) + c_2\cdot(0.22)^2 - 5.71 \right)\cdot 1+\\
&2\cdot\left(c_0 + c_1\cdot(0.55) + c_2\cdot(0.55)^2 - 5.30 \right)\cdot 1=0
\end{split}
\end{gather*}

Коэффициенты первой строки матрицы $\mathbf{A}$
и первый элемент вектора $\vect{b}$:
\begin{gather*}
\begin{array}{lcl}
a_{00}&=&1+1+1+1+1=5\\
a_{01}&=&(-0.76) + (-0.48) + (-0.09) + (0.22) + (0.55) = -0.56\\
a_{02}&=&(-0.76)^2 + (-0.48)^2 + (-0.09)^2 + (0.22)^2 + (0.55)^2=1.18\\
%
b_0&=&5.15 + 4.39 + 4.10 + 5.71 + 5.30=24.65
\end{array}
\end{gather*}

\item
Определим частную производную от меры отклонений 
$\rho(c_0,c_1,c_2)$ по аргументу $c_1$ и приравняем её нулю:
\begin{gather*}
\begin{split}
\pdiff{\rho}{c_1}=
&2\cdot\left(c_0 + c_1\cdot(-0.76) + c_2\cdot(-0.76)^2 - 5.15 \right)\cdot(-0.76)+\\
&2\cdot\left(c_0 + c_1\cdot(-0.48) + c_2\cdot(-0.48)^2 - 4.39 \right)\cdot(-0.48)+\\
&2\cdot\left(c_0 + c_1\cdot(-0.09) + c_2\cdot(-0.09)^2 - 4.10 \right)\cdot(-0.09)+\\
&2\cdot\left(c_0 + c_1\cdot(0.22) + c_2\cdot(0.22)^2 - 5.71 \right)\cdot(0.22)+\\
&2\cdot\left(c_0 + c_1\cdot(0.55) + c_2\cdot(0.55)^2 - 5.30 \right)\cdot(0.55)=0
\end{split}
\end{gather*}

Коэффициенты второй строки матрицы $\mathbf{A}$
и второй элемент вектора $\vect{b}$:
\begin{gather*}
\begin{array}{lcl}
c_{10}&=&(-0.76) + (-0.48) + (-0.09) + (0.22) + (0.55) = -0.56\\
c_{11}&=&(-0.76)^2 + (-0.48)^2 + (-0.09)^2 + (0.22)^2 + (0.55)^2=1.18\\
c_{12}&=&(-0.76)^3 + (-0.48)^3 + (-0.09)^3 + (0.22)^3 + (0.55)^3=-0.38\\
%
b_1&=&5.15\cdot(-0.76)+4.39\cdot(-0.48)+4.10\cdot(-0.09)+\\
&&5.71\cdot(0.22)+5.30\cdot(0.55)=-2.24
\end{array}
\end{gather*}

\item
Определим частную производную от меры отклонений 
$\rho(c_0,c_1,c_2)$ по аргументу $c_2$ и приравняем её нулю:
\begin{gather*}
\begin{split}
\pdiff{\rho}{c_2}=
&2\cdot\left(c_0 + c_1\cdot(-0.76) + c_2\cdot(-0.76)^2 - 5.15 \right)\cdot(-0.76)^2+\\
+&2\cdot\left(c_0 + c_1\cdot(-0.48) + c_2\cdot(-0.48)^2 - 4.39 \right)\cdot(-0.48)^2+\\
+&2\cdot\left(c_0 + c_1\cdot(-0.09) + c_2\cdot(-0.09)^2 - 4.10 \right)\cdot(-0.09)^2+\\
+&2\cdot\left(c_0 + c_1\cdot(0.22) + c_2\cdot(0.22)^2 - 5.71 \right)\cdot(0.22)^2+\\
+&2\cdot\left(c_0 + c_1\cdot(0.55) + c_2\cdot(0.55)^2 - 5.30 \right)\cdot(0.55)^2=0
\end{split}
\end{gather*}

Коэффициенты третьей строки матрицы $\mathbf{A}$
и третий элемент вектора $\vect{b}$:
\begin{gather*}
\begin{array}{lcl}
c_{20}&=&(-0.76)^2 + (-0.48)^2 + (-0.09)^2 + (0.22)^2 + (0.55)^2=1.18\\
c_{21}&=&(-0.76)^3 + (-0.48)^3 + (-0.09)^3 + (0.22)^3 + (0.55)^3=-0.38\\
c_{22}&=&(-0.76)^4 + (-0.48)^4 + (-0.09)^4 + (0.22)^4 + (0.55)^4=0.49\\
%
b_2&=&5.15\cdot(-0.76)^2 +4.39\cdot(-0.48)^2 +4.10\cdot(-0.09)^2+\\
&&5.71\cdot(0.22)^2 +5.30\cdot(0.55)^2=5.94
\end{array}
\end{gather*}

\item
Таким образом, для определения неизвестных коэффициентов 
$c_0,c_1,c_2$ аппроксимирующего полинома $p_2(x)$ 
необходимо решить систему линейных алгебраических уравнений:
\begin{equation*}
\begin{pmatrix}[rrr]
5&-0.56&1.18\\
-0.56&1.18&-0.38\\
1.18&-0.38&0.49\\
\end{pmatrix}\cdot
\begin{pmatrix}c_0\\c_1\\c_2\end{pmatrix}
=\begin{pmatrix}24.65\\-2.24\\5.94\\\end{pmatrix}
\end{equation*}

\item
Решение этой системы линейных уравнений можно найти методом Гаусса:
\begin{gather*}
\left\{\begin{array}{lcl}
c_0&=&4.66\\
c_1&=&0.80\\
c_2&=&1.52
\end{array}\right.
\end{gather*}

Таким образом, аппроксимирующий полином имеет вид:
\begin{equation}\label{eq:my approx polynom}
p_2(x)=4.66 + 0.80\cdot x + 1.52\cdot x^2
\end{equation}

\item
На одном графике представим диаграмму рассеяния 
(разброса) данных функции заданной таблично $y_i=f(x_i)$
(маркеры) и результаты вычислений
аппроксимирующего алгебраического полинома 
второго порядка $p_2(x)$ (сплошная линия).
% *******************************
%	График функций
%
\begin{figure}[H]\centering
\begin{tikzpicture}
\begin{axis}[% оси координат
ylabel={$p_2(x)$},
xmin=-1, xmax=0.7, xtick={-0.8,-0.4,0,0.4},
ymin=3.8, ymax=6,
]
\addplot[ball darkblue,only marks]
coordinates{(-0.76,5.15) (-0.48,4.39) (-0.09,4.10) (0.22,5.71) (0.55,5.30)};
\addplot[darkblue,mark=none,domain=-0.9:0.6, samples=50] 
{4.66 + 0.80*x + 1.52*x^2} node[pos=0.5,below right] {$p_2(x)$};
\end{axis}
\end{tikzpicture}
\caption{График таблично заданной функции $y_i=f(x_i)$ (маркеры) 
и аппроксимирующего алгебраического полинома $p_2(x)$
(сплошная линия)}
\end{figure}

\item
Рассчитаем значения аппроксимирующего полинома 
\eqref{eq:my approx polynom} и ошибку аппроксимации 
таблично заданной функции в узлах сетки $\{x_i\}$
(таблица \ref{tab:approx calculate data}):
\begin{gather}
\epsilon_i=y_i-p_2(x_i)
\end{gather}
%
% Таблица: погрешность аппроксимации
%
\begin{table}[H]
\caption{Рассчитанные значения аппроксимирующего полинома $p_2(x)$}
\label{tab:approx calculate data}
\begin{tabular*}{\textwidth}{%
l@{\extracolsep{\fill}}*{5}{r}p{0.25cm}}
\toprule
$i$&$0$&$1$&$2$&$3$&$4$\\
\midmidrule
$x_i$&$-0.76$&$-0.48$&$-0.09$&$0.22$&$0.55$\\
$y_i$&$5.15$&$4.39$&$4.10$&$5.71$&$5.30$\\
$p_2(x_i)$	&	$4.93$	&	$4.63$	&	$4.60$	&	$4.91$	&	$5.56$\\
$\epsilon_i$	&	$0.22$	&	$-0.24$	&	$-0.50$	&	$0.80$	&	$-0.26$\\
\bottomrule
\end{tabular*}
\end{table}

%
% График
%
\begin{figure}[H]\centering
\begin{tikzpicture}
\begin{axis}[xmin=-1, xmax=0.7, xtick={-0.8,-0.4,0,0.4},
ymin=-1, ymax=1,
xlabel=$x_i$,ylabel={$\epsilon_i=y_i-p(x_i)$}]
\addplot[ycomb,draw=darkred,mark=*,mark size=3pt,mark options={fill=white}]
coordinates{(-0.76,0.22)(-0.48,-0.24)(-0.09,-0.50)(0.22,0.80)(0.55,-0.26)};
\end{axis}
\end{tikzpicture}
\caption{Ошибка аппроксимации полином $p(x)$
функции заданной таблично $y_i=f(x_i)$}
\label{fig:error}
\end{figure}

\item
Рассчитаем среднее квадратичное отклонение 
$\delta$ полинома \eqref{eq:my approx polynom} от значений 
функции $\{y_i\}$ в узлах сетки $\{x_i\}$:
\begin{gather}
\delta = \dfrac{1}{n}\cdot\sum_{i=0}^{n-1}\epsilon_i^2=
\dfrac{0.05+0.06+0.25+0.64+0.07}{5}=0.213,
\end{gather}
где $n=5$ -- количество узлов сетки.


\end{enumerate}

\end{document}
Получилась система n+1 уравнений с таким же количеством 
неизвестных аj, причем линейная относительно этих переменных. 
Эта система называется системой нормальных уравнений. 
Из ее решения находятся параметры аj аппроксимирующей функции, 
обеспечивающие minR, т.е. наилучшее возможное квадратичное 
приближение. 

Зная коэффициенты, можно (если нужно) вычислить и величину R 
(например, для сравнения различных аппроксимирующих функций). 
Следует помнить, что при изменении даже одного значения 
исходных данных (или пары значений хi, уi, или одного из них) 
все коэффициенты изменят в общем случае свои значения, 
так как они полностью определяются исходными данными. 
Поэтому при повторении аппроксимации с несколько 
изменившимися данными (например, вследствие погрешностей 
измерения, помех, влияния неучтенных факторов и т.п.) 
получится другая аппроксимирующая функция, 
отличающаяся коэффициентами. 

Обратим внимание на то, что коэффициенты аj полинома находятся 
из решения системы уравнений, т.е. они связаны между собой. 
Это приводит к тому, что если какой-то коэффициент вследствие 
его малости захочется отбросить, придется пересчитывать 
заново оставшиеся. 

Можно рассчитать количественные оценки тесноты связи 
коэффициентов. Существует специальная теория планирования 
экспериментов, которая позволяет обосновать и рассчитать 
значения хi, используемые для аппроксимации, 
чтобы получить заданные свойства коэффициентов 
(несвязанность, минимальная дисперсия коэффициентов и т.д.) 
или аппроксимирующей функции (равная точность описания 
реальной зависимости в различных направлениях, 
минимальная дисперсия предсказания значения функции и т.д.).

В случае постановки другой задачи -- найти аппроксимирующую 
функцию, обеспечивающую погрешность не хуже заданной, -- 
необходимо подбирать и структуру этой функции. 
Эта задача значительно сложнее предыдущей 
(найти параметры аппроксимирующей функции заданной структуры, 
обеспечивающей наилучшую возможную погрешность) и 
решается в основном путем перебора различных функций и 
сравнения получающихся мер близости. 
Для примера на рис. 3.7 приведены для визуального 
сравнения исходная и аппроксимирующие функции с различной 
степенью полинома, т.е. функции с различной структурой. 

Не следует забывать, что с повышением точности аппроксимации 
растет и сложность функции (при полиномиальных 
аппроксимирующих функциях), что делает ее менее удобной 
при использовании.

Пример 3.1. В ходе проведения эксперимента были получены данные, 
представленные в таблице 3.1. Необходимо способом наименьших 
квадратов подобрать для заданных значений x и y квадратичную 
функцию . 

Построить на одной координатной плоскости экспериментальные 
данные и аппроксимирующую функцию.

Исходными данными для решения задачи является таблица 
наблюдений – набор значений независимых переменных и 
соответствующие им значения функции отклика. 
Число строк (узлов) таблично заданной функции m называют 
объемом выборки.

Форма уравнения выбирается исследователем в соответствии с 
поведением аппроксимируемой функции в области изменения 
независимых переменных. Результатом же решения задачи 
аппроксимации являются оценки коэффициентов этого уравнения. 

Очевидно, что коэффициенты уравнения следует подбирать так, 
чтобы рассчитываемые по уравнению значения функции отклика 
максимально близко совпадали с заданными в исходной таблице 
наблюдений.

http://ru.bmstu.wiki/Аппроксимация_функций,_моделирующих_сигналы
Математические модели сигналов, детально и точно описывающие 
определенные физические объекты и процессы, могут быть очень 
сложными и мало пригодными для практического использования, 
как при математическом анализе физических данных, 
так и в прикладных задачах, основанных на математическом 
моделировании КПС. Кроме того, практическая регистрация 
сигналов выполняется, как правило, с определенной погрешностью 
или с определенным уровнем шумов, которые по своим значениям 
могут быть выше теоретической погрешности прогнозирования 
сигналов при расчетах по сложным, хотя и очень точным формулам. 
Не имеет большого смысла и проектирование систем обработки 
и анализа сигналов по высокоточным формулам, 
если повышение точности расчетов не дает ощутимого эффекта 
в повышении точности обработки данных. 

Во всех этих условиях возникает задача аппроксимации --
представления произвольных сложных функций 
простыми и удобными для практического использования функциями 
таким образом, чтобы отклонение 
в области ее задания было наименьшим по определенному критерию 
приближения. 

Математика очень часто оперирует со специальными математическими 
функциями решения дифференциальных уравнений и интегралов, 
которые не имеют аналитических выражений и представляются 
табличными числовыми значениями 
для дискретных значений независимых переменных 

Аналогичными таблицами могут представляться и 
экспериментальные данные. Точки, в которых определены 
дискретные значения функций или данных, называются узловыми. 
Однако на практике могут понадобиться значения данных величин 
совсем в других точках, отличных от узловых, или с другим шагом 
дискретизации аргументов. 

Возникающая при этом задача вычисления значений функции 
в промежутках между узами называется задачей интерполяции, 
за пределами семейства узловых точек вперед или назад по 
переменным -- задачей экстраполяции или прогнозирования. 
Решение этих задач также обычно выполняется с использованием 
аппроксимирующих функций.

Сглаживание статистических данных или аппроксимация данных 
с учетом их статистических параметров относится к задачам регрессии,
и рассматриваются в следующей теме. 

Как правило, при регрессионном анализе усреднение данных 
производится методом наименьших квадратов (МНК).

Все вышеперечисленные задачи относятся к задачам 
приближения сигналов и функций и имеют многовековую историю,
в процессе которой сформировались классические математические 
методы аппроксимации, интерполяции, экстраполяции и регрессии 
функций. 

В рамках настоящего курса мы не будем углубляться в 
строгую математическую теорию этих операций. 
Все современные математические системы (Mathcad, MATLAB, Maple и пр.) 
имеют в своем составе универсальный аппарат выполнения таких операций,
дающий пользователю возможность реализации любых 
практических задач по обработке данных без отвлечения 
на теоретические подробности их исполнения. 
